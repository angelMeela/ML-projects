{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMntuo4h3jUNeE5HAtgIox0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelMeela/ML-projects/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtLiqLjrJKjI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e367cd31"
      },
      "source": [
        "# Task\n",
        "Design a mini-project for anomaly detection on the dataset \"/content/equipment_anomaly_data.csv\" using big data tools and machine learning, and prepare a report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8071273a"
      },
      "source": [
        "## Project design\n",
        "\n",
        "### Subtask:\n",
        "Define the scope of the mini-project, including the problem to be solved (anomaly detection), the dataset to be used, the big data tools to be integrated, and the ML model to be applied.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "803c4573"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the scope of the mini-project based on the instructions provided.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f18cf14",
        "outputId": "81c1bff1-7ac0-4952-c89f-78cee8b2cc06"
      },
      "source": [
        "# 1. Problem to be solved:\n",
        "problem = \"Detecting anomalies in equipment sensor data to identify potential failures or unusual behavior.\"\n",
        "\n",
        "# 2. Dataset to be used:\n",
        "dataset_path = \"/content/equipment_anomaly_data.csv\"\n",
        "\n",
        "# 3. Big data tool(s) to be integrated:\n",
        "big_data_tools = [\"PySpark for data loading and initial processing\"]\n",
        "\n",
        "# 4. Machine learning model to be applied:\n",
        "ml_model = \"Isolation Forest\"\n",
        "justification = \"Isolation Forest is suitable for anomaly detection as it works well with high-dimensional data and is less sensitive to outliers than other methods. It's also efficient for large datasets.\"\n",
        "\n",
        "# 5. Expected output:\n",
        "expected_output = [\n",
        "    \"A trained anomaly detection model.\",\n",
        "    \"A report summarizing the findings, including identified anomalies and insights.\"\n",
        "]\n",
        "\n",
        "print(\"Mini-Project Scope:\")\n",
        "print(f\"Problem: {problem}\")\n",
        "print(f\"Dataset: {dataset_path}\")\n",
        "print(f\"Big Data Tools: {', '.join(big_data_tools)}\")\n",
        "print(f\"ML Model: {ml_model}\")\n",
        "print(f\"Justification for ML Model: {justification}\")\n",
        "print(\"Expected Output:\")\n",
        "for item in expected_output:\n",
        "    print(f\"- {item}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-Project Scope:\n",
            "Problem: Detecting anomalies in equipment sensor data to identify potential failures or unusual behavior.\n",
            "Dataset: /content/equipment_anomaly_data.csv\n",
            "Big Data Tools: PySpark for data loading and initial processing\n",
            "ML Model: Isolation Forest\n",
            "Justification for ML Model: Isolation Forest is suitable for anomaly detection as it works well with high-dimensional data and is less sensitive to outliers than other methods. It's also efficient for large datasets.\n",
            "Expected Output:\n",
            "- A trained anomaly detection model.\n",
            "- A report summarizing the findings, including identified anomalies and insights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52bd2ee4"
      },
      "source": [
        "## Data loading and exploration\n",
        "\n",
        "### Subtask:\n",
        "Load the `equipment_anomaly_data.csv` dataset using a big data tool (e.g., PySpark). Perform initial data exploration to understand the data structure, identify potential issues (missing values, outliers), and gain insights into the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ff8e25c"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries for PySpark and create a SparkSession.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80729869"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"EquipmentAnomalyDetection\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e049a45"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the data into a Spark DataFrame, display its schema, show the first few rows, and print the number of rows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5fc8771",
        "outputId": "17755d75-e353-4002-ce5a-fc84980c48eb"
      },
      "source": [
        "df = spark.read.csv(\"/content/equipment_anomaly_data.csv\", header=True, inferSchema=True)\n",
        "df.printSchema()\n",
        "df.show(5)\n",
        "print(f\"Number of rows: {df.count()}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- temperature: double (nullable = true)\n",
            " |-- pressure: double (nullable = true)\n",
            " |-- vibration: double (nullable = true)\n",
            " |-- humidity: double (nullable = true)\n",
            " |-- equipment: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- faulty: double (nullable = true)\n",
            "\n",
            "+-----------------+-----------------+-------------------+------------------+----------+-------------+------+\n",
            "|      temperature|         pressure|          vibration|          humidity| equipment|     location|faulty|\n",
            "+-----------------+-----------------+-------------------+------------------+----------+-------------+------+\n",
            "|58.18018003931781|25.02927765103301| 0.6065162172245139|45.694907104076414|   Turbine|      Atlanta|   0.0|\n",
            "|75.74071220894001|22.95401759548667| 2.3380947537510077|41.867406792614915|Compressor|      Chicago|   0.0|\n",
            "|71.35859424081657|27.27683031893662| 1.3891983049086754| 58.95440890948324|   Turbine|San Francisco|   0.0|\n",
            "|71.61698526704753|32.24292130393475| 1.7706896863176191| 40.56513821185597|      Pump|      Atlanta|   0.0|\n",
            "|66.50683203881802|45.19747079743589|0.34539798929557564|43.253794756433095|      Pump|     New York|   0.0|\n",
            "+-----------------+-----------------+-------------------+------------------+----------+-------------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Number of rows: 7672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcb72893"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate and display summary statistics for numerical columns and check for missing values in each column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7b221bc",
        "outputId": "11dc9e83-1ec0-4826-a12c-57d34b76dcbf"
      },
      "source": [
        "df.describe().show()\n",
        "\n",
        "from pyspark.sql.functions import col, sum\n",
        "\n",
        "df.select(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in df.columns)).show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+--------------------+------------------+----------+-------------+-------------------+\n",
            "|summary|       temperature|          pressure|           vibration|          humidity| equipment|     location|             faulty|\n",
            "+-------+------------------+------------------+--------------------+------------------+----------+-------------+-------------------+\n",
            "|  count|              7672|              7672|                7672|              7672|      7672|         7672|               7672|\n",
            "|   mean| 70.92247815645658|35.738048287949084|  1.6118091973524176|50.016573581920284|      NULL|         NULL|0.09997393117831074|\n",
            "| stddev| 16.20005890567922|10.381593069378281|  0.7285601038822835|11.841478762776903|      NULL|         NULL|0.29998478968659514|\n",
            "|    min|10.269384763629008| 3.620797987053262|-0.42818766462029845|10.215076711940103|Compressor|      Atlanta|                0.0|\n",
            "|    max| 149.6904197890206| 79.88773351925018|   4.990537369353191| 89.98471787562592|   Turbine|San Francisco|                1.0|\n",
            "+-------+------------------+------------------+--------------------+------------------+----------+-------------+-------------------+\n",
            "\n",
            "+-----------+--------+---------+--------+---------+--------+------+\n",
            "|temperature|pressure|vibration|humidity|equipment|location|faulty|\n",
            "+-----------+--------+---------+--------+---------+--------+------+\n",
            "|          0|       0|        0|       0|        0|       0|     0|\n",
            "+-----------+--------+---------+--------+---------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eef1a458"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Clean and preprocess the data for ML model training. This may involve handling missing values, scaling numerical features, encoding categorical features, and splitting the data into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54ebd86"
      },
      "source": [
        "**Reasoning**:\n",
        "Drop the 'faulty' column, identify numerical and categorical columns, create a feature list, and one-hot encode the categorical columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba4483d8",
        "outputId": "b42e8f8c-9e29-4598-fc20-6c6b222341ce"
      },
      "source": [
        "# Drop the 'faulty' column\n",
        "df_features = df.drop(\"faulty\")\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_cols = [col for col, dtype in df_features.dtypes if dtype == 'double']\n",
        "categorical_cols = [col for col, dtype in df_features.dtypes if dtype == 'string']\n",
        "\n",
        "# Create a list of features\n",
        "feature_cols = numerical_cols + categorical_cols\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\").fit(df_features) for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_encoded\") for col in categorical_cols]\n",
        "\n",
        "# Chain indexers and encoders into a pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(stages=indexers + encoders)\n",
        "df_encoded = pipeline.fit(df_features).transform(df_features)\n",
        "\n",
        "# Update feature_cols to include encoded categorical features and numerical features\n",
        "encoded_categorical_cols = [col + \"_encoded\" for col in categorical_cols]\n",
        "feature_cols_processed = numerical_cols + encoded_categorical_cols\n",
        "\n",
        "df_encoded.printSchema()\n",
        "df_encoded.show(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- temperature: double (nullable = true)\n",
            " |-- pressure: double (nullable = true)\n",
            " |-- vibration: double (nullable = true)\n",
            " |-- humidity: double (nullable = true)\n",
            " |-- equipment: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- equipment_index: double (nullable = false)\n",
            " |-- location_index: double (nullable = false)\n",
            " |-- equipment_encoded: vector (nullable = true)\n",
            " |-- location_encoded: vector (nullable = true)\n",
            "\n",
            "+-----------------+-----------------+-------------------+------------------+----------+-------------+---------------+--------------+-----------------+----------------+\n",
            "|      temperature|         pressure|          vibration|          humidity| equipment|     location|equipment_index|location_index|equipment_encoded|location_encoded|\n",
            "+-----------------+-----------------+-------------------+------------------+----------+-------------+---------------+--------------+-----------------+----------------+\n",
            "|58.18018003931781|25.02927765103301| 0.6065162172245139|45.694907104076414|   Turbine|      Atlanta|            1.0|           0.0|    (2,[1],[1.0])|   (4,[0],[1.0])|\n",
            "|75.74071220894001|22.95401759548667| 2.3380947537510077|41.867406792614915|Compressor|      Chicago|            0.0|           1.0|    (2,[0],[1.0])|   (4,[1],[1.0])|\n",
            "|71.35859424081657|27.27683031893662| 1.3891983049086754| 58.95440890948324|   Turbine|San Francisco|            1.0|           4.0|    (2,[1],[1.0])|       (4,[],[])|\n",
            "|71.61698526704753|32.24292130393475| 1.7706896863176191| 40.56513821185597|      Pump|      Atlanta|            2.0|           0.0|        (2,[],[])|   (4,[0],[1.0])|\n",
            "|66.50683203881802|45.19747079743589|0.34539798929557564|43.253794756433095|      Pump|     New York|            2.0|           3.0|        (2,[],[])|   (4,[3],[1.0])|\n",
            "+-----------------+-----------------+-------------------+------------------+----------+-------------+---------------+--------------+-----------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddbfc6fb"
      },
      "source": [
        "**Reasoning**:\n",
        "Assemble the processed features into a single vector column, split the data into training and testing sets, and cache the resulting dataframes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9346ba10",
        "outputId": "b5254beb-0a4f-490f-9705-02090d8d38b6"
      },
      "source": [
        "# Assemble features into a single vector column\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols_processed, outputCol=\"features\")\n",
        "df_assembled = assembler.transform(df_encoded)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_df, test_df = df_assembled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Cache the training and testing dataframes\n",
        "train_df.cache()\n",
        "test_df.cache()\n",
        "\n",
        "print(\"Training DataFrame count:\", train_df.count())\n",
        "print(\"Testing DataFrame count:\", test_df.count())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataFrame count: 6208\n",
            "Testing DataFrame count: 1464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c19a6702"
      },
      "source": [
        "## Big data tool integration\n",
        "\n",
        "### Subtask:\n",
        "Integrate a big data tool (e.g., PySpark) into the data processing pipeline to handle the dataset efficiently. This could involve using Spark DataFrames for transformations and feature engineering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56302913"
      },
      "source": [
        "## Ml model selection and training\n",
        "\n",
        "### Subtask:\n",
        "Select an appropriate ML model for anomaly detection (e.g., Isolation Forest, One-Class SVM). Train the selected model on the preprocessed training data using a big data tool if applicable (e.g., Spark MLlib).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc882376"
      },
      "source": [
        "**Reasoning**:\n",
        "Select, instantiate, and train the Isolation Forest model using scikit-learn on the training data by converting the Spark DataFrame to a Pandas DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9d54e27",
        "outputId": "0e9565b5-4152-4f09-f796-58721fc61b42"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the 'features' column of train_df to a Pandas DataFrame for scikit-learn\n",
        "# Extract the vectors and convert to a list of lists\n",
        "train_features_list = train_df.select(\"features\").rdd.map(lambda row: row.features.toArray().tolist()).collect()\n",
        "train_features_pd = pd.DataFrame(train_features_list)\n",
        "\n",
        "# Instantiate the Isolation Forest model\n",
        "# Setting contamination to 'auto' lets the algorithm decide based on the data,\n",
        "# or we can set it based on prior knowledge (e.g., 0.1 as approximately 10% faulty)\n",
        "isolation_forest_model = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "isolation_forest_model.fit(train_features_pd)\n",
        "\n",
        "print(\"Isolation Forest model trained successfully.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolation Forest model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f870acb8"
      },
      "source": [
        "## Model evaluation\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the testing data using appropriate metrics for anomaly detection (e.g., precision, recall, F1-score, ROC AUC).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9e2c042"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract the 'features' column from the `test_df` Spark DataFrame, convert it to a Pandas DataFrame, predict anomaly scores and labels using the trained Isolation Forest model, and extract the true labels from the original dataframe to prepare for evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "3a1e83b4",
        "outputId": "38d86599-93f7-47ca-fde3-655d630baa08"
      },
      "source": [
        "# 1. Extract 'features' column from test_df and convert to Pandas DataFrame\n",
        "test_features_list = test_df.select(\"features\").rdd.map(lambda row: row.features.toArray().tolist()).collect()\n",
        "test_features_pd = pd.DataFrame(test_features_list)\n",
        "\n",
        "# 2. Predict anomaly scores\n",
        "test_anomaly_scores = isolation_forest_model.decision_function(test_features_pd)\n",
        "\n",
        "# 3. Predict anomaly labels\n",
        "test_predicted_labels = isolation_forest_model.predict(test_features_pd)\n",
        "\n",
        "# 4. Extract true labels from the original df and align with test_df\n",
        "# To align, we can join the original df with the test_df.\n",
        "# We need to add a unique identifier to both dataframes before splitting to ensure correct joining.\n",
        "# Since we didn't add an ID before splitting, we'll assume the order is maintained for this example.\n",
        "# In a real-world scenario with Spark, it's safer to add a monotonic_id before splitting.\n",
        "# Given the context, we will proceed assuming the order is consistent after randomSplit.\n",
        "\n",
        "# Convert test_df to Pandas to align with test_features_pd\n",
        "test_df_pd = test_df.toPandas()\n",
        "\n",
        "# Extract the 'faulty' column from the original df for the rows corresponding to test_df\n",
        "# This assumes the order of rows in test_df corresponds to the order in test_df_pd\n",
        "test_true_labels = test_df_pd['faulty']\n",
        "\n",
        "# Adjust true labels: 1 (faulty) should be the positive class (anomaly), 0 (not faulty) is negative.\n",
        "# Adjust predicted labels: -1 (anomaly) should be the positive class, 1 (normal) is negative.\n",
        "# We can convert Isolation Forest's -1 to 1 and 1 to 0 to match the true labels (1 for anomaly, 0 for normal).\n",
        "test_predicted_labels_adjusted = [1 if label == -1 else 0 for label in test_predicted_labels]\n",
        "\n",
        "# Convert to numpy arrays for sklearn metrics\n",
        "test_true_labels_np = test_true_labels.to_numpy()\n",
        "test_predicted_labels_adjusted_np = np.array(test_predicted_labels_adjusted)\n",
        "\n",
        "print(\"Data prepared for evaluation.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'faulty'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'faulty'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-806594766.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Extract the 'faulty' column from the original df for the rows corresponding to test_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# This assumes the order of rows in test_df corresponds to the order in test_df_pd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtest_true_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'faulty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Adjust true labels: 1 (faulty) should be the positive class (anomaly), 0 (not faulty) is negative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'faulty'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dac7dc0"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that the 'faulty' column is not present in `test_df_pd`. This is because the 'faulty' column was dropped from `df_features` before splitting the data. To get the true labels for the test set, we need to extract the 'faulty' column from the *original* `df` Spark DataFrame and then align it with the `test_df` after the split. The safest way to do this is to join the original `df` with `test_df` using a common identifier or, if the order was preserved during the split (which is not guaranteed with `randomSplit`), extract the corresponding rows. Since adding an ID before splitting wasn't done, we will attempt to extract the 'faulty' column from the original `df` for the rows that are present in `test_df`. We can achieve this by converting both `df` and `test_df` to Pandas DataFrames and then filtering or merging. However, converting the entire original Spark DataFrame to Pandas might be memory-intensive. A better approach is to extract the original 'faulty' column and add it back to the `df_assembled` Spark DataFrame before splitting, or join `test_df` with a subset of the original `df` containing only the 'faulty' column and the columns used for splitting (if any) or row identifiers. Given the available dataframes, the simplest (though not the most robust) approach is to convert the original `df` to Pandas, convert `test_df` to Pandas, and then merge or filter to get the 'faulty' column corresponding to the test set. Let's assume for now that merging on the feature columns will work for this dataset to retrieve the correct 'faulty' labels for the test set.\n",
        "\n",
        "Let's refine the approach: Instead of relying on a perfect merge based on features, which is risky, let's reconsider how `test_df` was created. It's a random split of `df_assembled`. `df_assembled` contains all columns from `df_encoded` plus the 'features' vector. `df_encoded` contains columns from `df_features` plus the indexed and encoded categorical columns. `df_features` was created by dropping 'faulty' from the original `df`. This confirms that `test_df` does *not* contain the original 'faulty' column.\n",
        "\n",
        "To get the true labels for `test_df`, we need to get the 'faulty' column from the original `df` for the same rows that ended up in `test_df`. The most reliable way to do this post-split without a pre-existing ID is to join `test_df` (which has the original 'equipment' and 'location' columns along with the processed features) back to the original `df` using the original columns as a join key. However, joining on multiple columns can be slow.\n",
        "\n",
        "A simpler (but potentially less robust depending on the dataset's structure and whether duplicates exist based on the join keys) approach is to convert both the original `df` and `test_df` to Pandas and then merge.\n",
        "\n",
        "Let's try converting the relevant columns of the original `df` to Pandas and merging with `test_df_pd`. We'll merge on the original columns ('temperature', 'pressure', 'vibration', 'humidity', 'equipment', 'location') that are present in both.\n",
        "\n",
        "Let's try again, focusing on correctly extracting the true labels. We have `test_df`, which is a Spark DataFrame. We need to get the 'faulty' column for the same rows from the original `df`. We can convert `test_df` to Pandas (`test_df_pd`) and then join it with a Pandas version of the original `df` that *includes* the 'faulty' column.\n",
        "\n",
        "Let's try converting the original `df` to Pandas and then merging with `test_df_pd`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwNrVAwVLxHb",
        "outputId": "d46f1df7-09db-4d48-e1a8-4fbe3b6796c2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# 1. Extract 'features' column from test_df and convert to Pandas DataFrame\n",
        "test_features_list = test_df.select(\"features\").rdd.map(lambda row: row.features.toArray().tolist()).collect()\n",
        "test_features_pd = pd.DataFrame(test_features_list)\n",
        "\n",
        "# 2. Predict anomaly scores\n",
        "test_anomaly_scores = isolation_forest_model.decision_function(test_features_pd)\n",
        "\n",
        "# 3. Predict anomaly labels\n",
        "test_predicted_labels = isolation_forest_model.predict(test_features_pd)\n",
        "\n",
        "# 4. Extract true labels from the original df and align with test_df\n",
        "# Convert original df to Pandas DataFrame\n",
        "df_pd = df.toPandas()\n",
        "\n",
        "# Convert test_df to Pandas DataFrame to facilitate merging\n",
        "test_df_pd = test_df.toPandas()\n",
        "\n",
        "# Merge test_df_pd with the original df_pd to get the 'faulty' column.\n",
        "# We will merge on the original feature columns that are present in both.\n",
        "merge_cols = ['temperature', 'pressure', 'vibration', 'humidity', 'equipment', 'location']\n",
        "test_df_with_faulty = pd.merge(test_df_pd, df_pd[merge_cols + ['faulty']], on=merge_cols, how='left')\n",
        "\n",
        "# Extract the 'faulty' column as the true labels\n",
        "test_true_labels = test_df_with_faulty['faulty']\n",
        "\n",
        "# Adjust true labels: 1 (faulty) should be the positive class (anomaly), 0 (not faulty) is negative.\n",
        "# Adjust predicted labels: -1 (anomaly) should be the positive class, 1 (normal) is negative.\n",
        "# Convert Isolation Forest's -1 to 1 and 1 to 0 to match the true labels (1 for anomaly, 0 for normal).\n",
        "test_predicted_labels_adjusted = [1 if label == -1 else 0 for label in test_predicted_labels]\n",
        "\n",
        "# Convert to numpy arrays for sklearn metrics\n",
        "test_true_labels_np = test_true_labels.to_numpy()\n",
        "test_predicted_labels_adjusted_np = np.array(test_predicted_labels_adjusted)\n",
        "\n",
        "# 5. Calculate evaluation metrics\n",
        "# Precision, Recall, F1-score require binary classification labels\n",
        "precision = precision_score(test_true_labels_np, test_predicted_labels_adjusted_np)\n",
        "recall = recall_score(test_true_labels_np, test_predicted_labels_adjusted_np)\n",
        "f1 = f1_score(test_true_labels_np, test_predicted_labels_adjusted_np)\n",
        "\n",
        "# ROC AUC requires predicted scores and true labels\n",
        "# The decision_function gives a score where lower values are more anomalous.\n",
        "# For ROC AUC, we need a score where higher values indicate the positive class (anomaly).\n",
        "# So, we can use the negative of the decision function scores.\n",
        "# Also, ROC AUC requires the true labels to be 0 and 1, which we already have in test_true_labels_np.\n",
        "roc_auc = roc_auc_score(test_true_labels_np, -test_anomaly_scores)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(test_true_labels_np, test_predicted_labels_adjusted_np)\n",
        "\n",
        "\n",
        "# 6. Print the calculated evaluation metrics\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8345\n",
            "Recall: 0.8467\n",
            "F1-score: 0.8406\n",
            "ROC AUC: 0.9732\n",
            "Confusion Matrix:\n",
            "[[1304   23]\n",
            " [  21  116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf7fc86b"
      },
      "source": [
        "## Anomaly detection and analysis\n",
        "\n",
        "### Subtask:\n",
        "Use the trained model to predict anomalies in the dataset. Analyze the detected anomalies to understand their characteristics and potential causes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b77301d"
      },
      "source": [
        "**Reasoning**:\n",
        "Predict anomaly scores and labels for the entire dataset, add them to the original DataFrame, and filter for detected anomalies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba268bc5",
        "outputId": "60d0a103-5dee-44bd-e0fa-90e547d4b7cf"
      },
      "source": [
        "# 1. Predict anomaly scores for the entire dataset (using df_assembled)\n",
        "# Convert df_assembled to Pandas DataFrame for scikit-learn prediction\n",
        "df_assembled_pd = df_assembled.select(\"features\").rdd.map(lambda row: row.features.toArray().tolist()).collect()\n",
        "df_assembled_pd = pd.DataFrame(df_assembled_pd)\n",
        "\n",
        "# Predict anomaly scores\n",
        "all_anomaly_scores = isolation_forest_model.decision_function(df_assembled_pd)\n",
        "\n",
        "# 2. Predict anomaly labels for the entire dataset\n",
        "all_predicted_labels = isolation_forest_model.predict(df_assembled_pd)\n",
        "\n",
        "# Adjust predicted labels to match the original 'faulty' column format (1 for anomaly, 0 for normal)\n",
        "all_predicted_labels_adjusted = [1 if label == -1 else 0 for label in all_predicted_labels]\n",
        "\n",
        "# 3. Add the anomaly scores and predicted labels as new columns to the original Spark DataFrame df\n",
        "from pyspark.sql.types import DoubleType, IntegerType\n",
        "from pyspark.sql.functions import col, udf\n",
        "\n",
        "# Create Pandas Series for scores and labels\n",
        "scores_series = pd.Series(all_anomaly_scores)\n",
        "labels_series = pd.Series(all_predicted_labels_adjusted)\n",
        "\n",
        "# Convert Spark DataFrame to Pandas to add the new columns\n",
        "df_pd_with_predictions = df.toPandas()\n",
        "\n",
        "# Add the scores and labels as new columns\n",
        "df_pd_with_predictions['anomaly_score'] = scores_series\n",
        "df_pd_with_predictions['predicted_anomaly'] = labels_series\n",
        "\n",
        "# Convert the Pandas DataFrame back to Spark DataFrame\n",
        "df_with_predictions = spark.createDataFrame(df_pd_with_predictions)\n",
        "\n",
        "# 4. Filter the DataFrame to show only the detected anomalies (where the predicted label indicates an anomaly)\n",
        "anomalies_df = df_with_predictions.filter(col(\"predicted_anomaly\") == 1)\n",
        "\n",
        "# 5. Display the first few rows of the DataFrame containing only the detected anomalies and their scores\n",
        "anomalies_df.show(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+-------------------+------------------+----------+-------------+------+--------------------+-----------------+\n",
            "|       temperature|          pressure|          vibration|          humidity| equipment|     location|faulty|       anomaly_score|predicted_anomaly|\n",
            "+------------------+------------------+-------------------+------------------+----------+-------------+------+--------------------+-----------------+\n",
            "|  49.5109594501023| 76.42672868018283|  4.809297752752174|20.269692247772895|Compressor|     New York|   1.0|-0.12466146703124403|                1|\n",
            "|148.92336873207364|22.214121367591716|0.10981888071321333|39.944953294698905|   Turbine|San Francisco|   1.0|-0.03363523837066429|                1|\n",
            "|141.26030984408388| 54.23905839448483| 2.7256907331768128| 86.39046563060697|      Pump|      Atlanta|   1.0|-0.08414630224300623|                1|\n",
            "| 83.73658545162958| 53.44757268774192| 1.6430079038173124|  25.5250485765034|   Turbine|     New York|   0.0|-0.02036187575325643|                1|\n",
            "|117.25565678109554| 76.17469161652276|  3.255742838577201|  82.1430583176929|      Pump|     New York|   1.0|-0.11227118867414043|                1|\n",
            "+------------------+------------------+-------------------+------------------+----------+-------------+------+--------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66a081d7"
      },
      "source": [
        "**Reasoning**:\n",
        "Analyze the characteristics of the detected anomalies by examining the feature distributions and grouping by categorical features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "1e5c1a65",
        "outputId": "cf653f46-4443-46d5-f013-e89ffee5b790"
      },
      "source": [
        "# 6. Analyze the characteristics of the detected anomalies\n",
        "# Convert anomalies_df to Pandas for easier analysis and visualization\n",
        "anomalies_pd = anomalies_df.toPandas()\n",
        "\n",
        "# Display descriptive statistics for numerical features of anomalies\n",
        "print(\"Descriptive statistics for numerical features in detected anomalies:\")\n",
        "display(anomalies_pd[['temperature', 'pressure', 'vibration', 'humidity', 'anomaly_score']].describe())\n",
        "\n",
        "# 7. Consider grouping or summarizing the anomalies by categorical features\n",
        "print(\"\\nAnomaly counts by equipment type:\")\n",
        "display(anomalies_pd['equipment'].value_counts())\n",
        "\n",
        "print(\"\\nAnomaly counts by location:\")\n",
        "display(anomalies_pd['location'].value_counts())\n",
        "\n",
        "# 8. Briefly summarize the key characteristics observed in the detected anomalies.\n",
        "# This step will be done as a concluding remark after the analysis."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptive statistics for numerical features in detected anomalies:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       temperature    pressure   vibration    humidity  anomaly_score\n",
              "count   760.000000  760.000000  760.000000  760.000000     760.000000\n",
              "mean     79.935586   40.955373    2.465996   50.985919      -0.055307\n",
              "std      39.994741   21.518243    1.474946   23.335907       0.038514\n",
              "min      10.269385    3.620798   -0.167446   10.215077      -0.165170\n",
              "25%      44.642111   22.195602    1.129491   29.386059      -0.084687\n",
              "50%      83.043784   39.718277    2.479675   53.618424      -0.051516\n",
              "75%     114.692447   58.771977    3.768034   70.616874      -0.020608\n",
              "max     149.690420   79.887734    4.990537   89.984718      -0.000026"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28b6b6b4-e590-43e1-a7a1-ee3d2cfd5ad7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature</th>\n",
              "      <th>pressure</th>\n",
              "      <th>vibration</th>\n",
              "      <th>humidity</th>\n",
              "      <th>anomaly_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>79.935586</td>\n",
              "      <td>40.955373</td>\n",
              "      <td>2.465996</td>\n",
              "      <td>50.985919</td>\n",
              "      <td>-0.055307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>39.994741</td>\n",
              "      <td>21.518243</td>\n",
              "      <td>1.474946</td>\n",
              "      <td>23.335907</td>\n",
              "      <td>0.038514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10.269385</td>\n",
              "      <td>3.620798</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>10.215077</td>\n",
              "      <td>-0.165170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>44.642111</td>\n",
              "      <td>22.195602</td>\n",
              "      <td>1.129491</td>\n",
              "      <td>29.386059</td>\n",
              "      <td>-0.084687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>83.043784</td>\n",
              "      <td>39.718277</td>\n",
              "      <td>2.479675</td>\n",
              "      <td>53.618424</td>\n",
              "      <td>-0.051516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>114.692447</td>\n",
              "      <td>58.771977</td>\n",
              "      <td>3.768034</td>\n",
              "      <td>70.616874</td>\n",
              "      <td>-0.020608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>149.690420</td>\n",
              "      <td>79.887734</td>\n",
              "      <td>4.990537</td>\n",
              "      <td>89.984718</td>\n",
              "      <td>-0.000026</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28b6b6b4-e590-43e1-a7a1-ee3d2cfd5ad7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28b6b6b4-e590-43e1-a7a1-ee3d2cfd5ad7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28b6b6b4-e590-43e1-a7a1-ee3d2cfd5ad7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9702963e-f680-4d81-86a3-479a61c7d8a2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9702963e-f680-4d81-86a3-479a61c7d8a2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9702963e-f680-4d81-86a3-479a61c7d8a2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# This step will be done as a concluding remark after the analysis\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 246.2922045248215,\n        \"min\": 10.269384763629008,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          79.9355860976409,\n          83.04378422235196,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 256.3212187525705,\n        \"min\": 3.620797987053262,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          40.95537269532013,\n          39.71827706693638,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vibration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 267.8900123569222,\n        \"min\": -0.16744635531291485,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.4659959928775432,\n          2.4796752255799523,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 253.45161616205323,\n        \"min\": 10.215076711940103,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          50.985918870166856,\n          53.618423600403794,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anomaly_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 268.7176956131716,\n        \"min\": -0.16516996149563967,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.05530687787542155,\n          -0.05151577488002518,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anomaly counts by equipment type:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "equipment\n",
              "Compressor    321\n",
              "Turbine       231\n",
              "Pump          208\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equipment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Compressor</th>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbine</th>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pump</th>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anomaly counts by location:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "location\n",
              "Chicago          174\n",
              "Atlanta          162\n",
              "New York         161\n",
              "Houston          161\n",
              "San Francisco    102\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chicago</th>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atlanta</th>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>New York</th>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Houston</th>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>San Francisco</th>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7bc5ed0"
      },
      "source": [
        "## Report preparation\n",
        "\n",
        "### Subtask:\n",
        "Prepare a comprehensive report summarizing the project, including the problem definition, data analysis, methodology, model details, results, and conclusions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "537795f5"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate the comprehensive report as a series of print statements, summarizing the project based on the previous steps and available variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b79644e0",
        "outputId": "6a757f83-7501-46d7-c2ce-74796dc5dd6d"
      },
      "source": [
        "print(\"## Equipment Anomaly Detection Project Report\\n\")\n",
        "\n",
        "print(\"### 1. Introduction\")\n",
        "print(\"This project aimed to detect anomalies in equipment sensor data to identify potential failures or unusual behavior. Early detection of anomalies can prevent costly breakdowns and improve maintenance efficiency.\\n\")\n",
        "\n",
        "print(\"### 2. Data\")\n",
        "print(\"The dataset used for this project is located at '/content/equipment_anomaly_data.csv'.\")\n",
        "print(\"It contains sensor readings and categorical information for various pieces of equipment.\")\n",
        "print(f\"The dataset has {df.count()} rows and the following columns:\")\n",
        "df.printSchema()\n",
        "print(\"\\nInitial data exploration showed no missing values and provided summary statistics for numerical features.\\n\")\n",
        "\n",
        "print(\"### 3. Methodology\")\n",
        "print(\"The approach involved several steps to prepare the data for anomaly detection using the Isolation Forest model:\")\n",
        "print(\"- **Data Preprocessing:** The 'faulty' column was initially separated as it represents the true anomaly labels for evaluation.\")\n",
        "print(\"  Categorical features ('equipment' and 'location') were one-hot encoded using Spark's StringIndexer and OneHotEncoder.\")\n",
        "print(\"  Numerical and encoded categorical features were assembled into a single feature vector using VectorAssembler.\")\n",
        "print(\"- **Train-Test Split:** The data was split into an 80/20 training and testing set.\")\n",
        "print(\"- **Model Selection:** Isolation Forest was chosen as the anomaly detection model due to its effectiveness in isolating anomalies and its efficiency with large datasets.\")\n",
        "print(\"- **Model Training:** The Isolation Forest model was trained on the preprocessed training data.\\n\")\n",
        "\n",
        "print(\"### 4. Model Training and Evaluation\")\n",
        "print(\"An Isolation Forest model with n_estimators=100 and contamination=0.1 (estimated proportion of anomalies) was trained.\")\n",
        "print(\"The model's performance was evaluated on the test set using standard anomaly detection metrics:\")\n",
        "print(f\"- **Precision:** {precision:.4f}\")\n",
        "print(f\"- **Recall:** {recall:.4f}\")\n",
        "print(f\"- **F1-score:** {f1:.4f}\")\n",
        "print(f\"- **ROC AUC:** {roc_auc:.4f}\")\n",
        "print(\"The Confusion Matrix for the test set is:\")\n",
        "print(conf_matrix)\n",
        "print(\"Interpretation of metrics:\")\n",
        "print(f\"- Precision of {precision:.4f} indicates that {precision*100:.2f}% of the instances predicted as anomalies were actually faulty.\")\n",
        "print(f\"- Recall of {recall:.4f} indicates that the model correctly identified {recall*100:.2f}% of all actual faulty instances.\")\n",
        "print(f\"- The F1-score of {f1:.4f} is the harmonic mean of precision and recall, providing a balanced measure of the model's accuracy.\")\n",
        "print(f\"- An ROC AUC of {roc_auc:.4f} indicates excellent discrimination ability of the model in distinguishing between normal and anomalous instances.\\n\")\n",
        "\n",
        "print(\"### 5. Anomaly Detection and Analysis\")\n",
        "print(\"The trained Isolation Forest model was used to predict anomaly scores and labels for the entire dataset.\")\n",
        "print(f\"A total of {anomalies_df.count()} anomalies were detected based on the model's predictions.\")\n",
        "print(\"Analysis of the detected anomalies revealed the following characteristics:\")\n",
        "print(\"\\nDescriptive statistics for numerical features in detected anomalies:\")\n",
        "display(anomalies_pd[['temperature', 'pressure', 'vibration', 'humidity', 'anomaly_score']].describe())\n",
        "print(\"\\nAnomaly counts by equipment type:\")\n",
        "display(anomalies_pd['equipment'].value_counts())\n",
        "print(\"\\nAnomaly counts by location:\")\n",
        "display(anomalies_pd['location'].value_counts())\n",
        "print(\"\\nThe analysis shows that anomalies are distributed across all equipment types and locations, with Compressors and locations like Chicago, Atlanta, and New York showing higher counts of detected anomalies.\\n\")\n",
        "\n",
        "print(\"### 6. Conclusion\")\n",
        "print(\"This project successfully implemented an anomaly detection system for equipment sensor data using PySpark for data processing and scikit-learn's Isolation Forest model.\")\n",
        "print(\"The model demonstrated strong performance on the test set, as indicated by high precision, recall, F1-score, and ROC AUC.\")\n",
        "print(\"The anomaly analysis provided insights into the distribution of anomalies across different equipment types and locations.\")\n",
        "print(\"The detected anomalies can be further investigated to understand the underlying causes of unusual equipment behavior.\")\n",
        "print(\"Potential next steps include:\")\n",
        "print(\"- Investigating the specific characteristics of anomalies for each equipment type and location.\")\n",
        "print(\"- Implementing real-time anomaly detection on streaming sensor data.\")\n",
        "print(\"- Exploring other anomaly detection algorithms and comparing their performance.\")\n",
        "print(\"- Incorporating domain expertise to refine the anomaly detection threshold and interpret the results.\")\n",
        "print(\"\\nReport generation complete.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Equipment Anomaly Detection Project Report\n",
            "\n",
            "### 1. Introduction\n",
            "This project aimed to detect anomalies in equipment sensor data to identify potential failures or unusual behavior. Early detection of anomalies can prevent costly breakdowns and improve maintenance efficiency.\n",
            "\n",
            "### 2. Data\n",
            "The dataset used for this project is located at '/content/equipment_anomaly_data.csv'.\n",
            "It contains sensor readings and categorical information for various pieces of equipment.\n",
            "The dataset has 7672 rows and the following columns:\n",
            "root\n",
            " |-- temperature: double (nullable = true)\n",
            " |-- pressure: double (nullable = true)\n",
            " |-- vibration: double (nullable = true)\n",
            " |-- humidity: double (nullable = true)\n",
            " |-- equipment: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- faulty: double (nullable = true)\n",
            "\n",
            "\n",
            "Initial data exploration showed no missing values and provided summary statistics for numerical features.\n",
            "\n",
            "### 3. Methodology\n",
            "The approach involved several steps to prepare the data for anomaly detection using the Isolation Forest model:\n",
            "- **Data Preprocessing:** The 'faulty' column was initially separated as it represents the true anomaly labels for evaluation.\n",
            "  Categorical features ('equipment' and 'location') were one-hot encoded using Spark's StringIndexer and OneHotEncoder.\n",
            "  Numerical and encoded categorical features were assembled into a single feature vector using VectorAssembler.\n",
            "- **Train-Test Split:** The data was split into an 80/20 training and testing set.\n",
            "- **Model Selection:** Isolation Forest was chosen as the anomaly detection model due to its effectiveness in isolating anomalies and its efficiency with large datasets.\n",
            "- **Model Training:** The Isolation Forest model was trained on the preprocessed training data.\n",
            "\n",
            "### 4. Model Training and Evaluation\n",
            "An Isolation Forest model with n_estimators=100 and contamination=0.1 (estimated proportion of anomalies) was trained.\n",
            "The model's performance was evaluated on the test set using standard anomaly detection metrics:\n",
            "- **Precision:** 0.8345\n",
            "- **Recall:** 0.8467\n",
            "- **F1-score:** 0.8406\n",
            "- **ROC AUC:** 0.9732\n",
            "The Confusion Matrix for the test set is:\n",
            "[[1304   23]\n",
            " [  21  116]]\n",
            "Interpretation of metrics:\n",
            "- Precision of 0.8345 indicates that 83.45% of the instances predicted as anomalies were actually faulty.\n",
            "- Recall of 0.8467 indicates that the model correctly identified 84.67% of all actual faulty instances.\n",
            "- The F1-score of 0.8406 is the harmonic mean of precision and recall, providing a balanced measure of the model's accuracy.\n",
            "- An ROC AUC of 0.9732 indicates excellent discrimination ability of the model in distinguishing between normal and anomalous instances.\n",
            "\n",
            "### 5. Anomaly Detection and Analysis\n",
            "The trained Isolation Forest model was used to predict anomaly scores and labels for the entire dataset.\n",
            "A total of 760 anomalies were detected based on the model's predictions.\n",
            "Analysis of the detected anomalies revealed the following characteristics:\n",
            "\n",
            "Descriptive statistics for numerical features in detected anomalies:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       temperature    pressure   vibration    humidity  anomaly_score\n",
              "count   760.000000  760.000000  760.000000  760.000000     760.000000\n",
              "mean     79.935586   40.955373    2.465996   50.985919      -0.055307\n",
              "std      39.994741   21.518243    1.474946   23.335907       0.038514\n",
              "min      10.269385    3.620798   -0.167446   10.215077      -0.165170\n",
              "25%      44.642111   22.195602    1.129491   29.386059      -0.084687\n",
              "50%      83.043784   39.718277    2.479675   53.618424      -0.051516\n",
              "75%     114.692447   58.771977    3.768034   70.616874      -0.020608\n",
              "max     149.690420   79.887734    4.990537   89.984718      -0.000026"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b5b2a6c-1abd-4ca3-ab8f-8133cf63aaf3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature</th>\n",
              "      <th>pressure</th>\n",
              "      <th>vibration</th>\n",
              "      <th>humidity</th>\n",
              "      <th>anomaly_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "      <td>760.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>79.935586</td>\n",
              "      <td>40.955373</td>\n",
              "      <td>2.465996</td>\n",
              "      <td>50.985919</td>\n",
              "      <td>-0.055307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>39.994741</td>\n",
              "      <td>21.518243</td>\n",
              "      <td>1.474946</td>\n",
              "      <td>23.335907</td>\n",
              "      <td>0.038514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10.269385</td>\n",
              "      <td>3.620798</td>\n",
              "      <td>-0.167446</td>\n",
              "      <td>10.215077</td>\n",
              "      <td>-0.165170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>44.642111</td>\n",
              "      <td>22.195602</td>\n",
              "      <td>1.129491</td>\n",
              "      <td>29.386059</td>\n",
              "      <td>-0.084687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>83.043784</td>\n",
              "      <td>39.718277</td>\n",
              "      <td>2.479675</td>\n",
              "      <td>53.618424</td>\n",
              "      <td>-0.051516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>114.692447</td>\n",
              "      <td>58.771977</td>\n",
              "      <td>3.768034</td>\n",
              "      <td>70.616874</td>\n",
              "      <td>-0.020608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>149.690420</td>\n",
              "      <td>79.887734</td>\n",
              "      <td>4.990537</td>\n",
              "      <td>89.984718</td>\n",
              "      <td>-0.000026</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b5b2a6c-1abd-4ca3-ab8f-8133cf63aaf3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b5b2a6c-1abd-4ca3-ab8f-8133cf63aaf3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b5b2a6c-1abd-4ca3-ab8f-8133cf63aaf3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-00014417-2206-4962-b36c-c9b74f90a1fc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00014417-2206-4962-b36c-c9b74f90a1fc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-00014417-2206-4962-b36c-c9b74f90a1fc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nReport generation complete\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 246.2922045248215,\n        \"min\": 10.269384763629008,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          79.9355860976409,\n          83.04378422235196,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 256.3212187525705,\n        \"min\": 3.620797987053262,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          40.95537269532013,\n          39.71827706693638,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vibration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 267.8900123569222,\n        \"min\": -0.16744635531291485,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.4659959928775432,\n          2.4796752255799523,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 253.45161616205323,\n        \"min\": 10.215076711940103,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          50.985918870166856,\n          53.618423600403794,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anomaly_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 268.7176956131716,\n        \"min\": -0.16516996149563967,\n        \"max\": 760.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.05530687787542155,\n          -0.05151577488002518,\n          760.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anomaly counts by equipment type:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "equipment\n",
              "Compressor    321\n",
              "Turbine       231\n",
              "Pump          208\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equipment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Compressor</th>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbine</th>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pump</th>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anomaly counts by location:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "location\n",
              "Chicago          174\n",
              "Atlanta          162\n",
              "New York         161\n",
              "Houston          161\n",
              "San Francisco    102\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chicago</th>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atlanta</th>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>New York</th>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Houston</th>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>San Francisco</th>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The analysis shows that anomalies are distributed across all equipment types and locations, with Compressors and locations like Chicago, Atlanta, and New York showing higher counts of detected anomalies.\n",
            "\n",
            "### 6. Conclusion\n",
            "This project successfully implemented an anomaly detection system for equipment sensor data using PySpark for data processing and scikit-learn's Isolation Forest model.\n",
            "The model demonstrated strong performance on the test set, as indicated by high precision, recall, F1-score, and ROC AUC.\n",
            "The anomaly analysis provided insights into the distribution of anomalies across different equipment types and locations.\n",
            "The detected anomalies can be further investigated to understand the underlying causes of unusual equipment behavior.\n",
            "Potential next steps include:\n",
            "- Investigating the specific characteristics of anomalies for each equipment type and location.\n",
            "- Implementing real-time anomaly detection on streaming sensor data.\n",
            "- Exploring other anomaly detection algorithms and comparing their performance.\n",
            "- Incorporating domain expertise to refine the anomaly detection threshold and interpret the results.\n",
            "\n",
            "Report generation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4c6e30d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset contains sensor readings, equipment type, location, and a 'faulty' label, with no missing values.\n",
        "*   Approximately 10% of the records in the original dataset are labeled as faulty.\n",
        "*   The Isolation Forest model trained on the data achieved strong performance on the test set with a Precision of 0.8345, Recall of 0.8467, F1-score of 0.8406, and an ROC AUC of 0.9732.\n",
        "*   The model identified 760 anomalies in the entire dataset.\n",
        "*   Anomalies were distributed across all equipment types, with Compressors showing the highest count (321).\n",
        "*   Anomalies were also distributed across all locations, with Chicago having the highest count (174).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Investigate the specific sensor readings and combinations of features that contribute to high anomaly scores for different equipment types and locations to understand the root causes of unusual behavior.\n",
        "*   Explore implementing this anomaly detection system in a real-time streaming environment to enable proactive maintenance and minimize equipment downtime.\n"
      ]
    }
  ]
}